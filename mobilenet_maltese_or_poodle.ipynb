{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gskumlehn/maltese-or-poodle/blob/main/mobilenet_maltese_or_poodle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k6DenICOqQ-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr33oWQ_OwZ_"
      },
      "source": [
        "Updates database from github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-zM04CJVzy1",
        "outputId": "5c900acd-0ffb-4e3d-d2c3-ac3e1794acdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'maltese-or-poodle'...\n",
            "remote: Enumerating objects: 981, done.\u001b[K\n",
            "remote: Counting objects: 100% (981/981), done.\u001b[K\n",
            "remote: Compressing objects: 100% (975/975), done.\u001b[K\n",
            "remote: Total 981 (delta 7), reused 972 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (981/981), 32.11 MiB | 26.47 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf maltese-or-poodle\n",
        "!git clone https://github.com/gskumlehn/maltese-or-poodle.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjAN0u3ePKE6"
      },
      "source": [
        "Creates two MobileNet models that share the same architecture and pre-trained weights but operate on different input layers:\n",
        "\n",
        "model: Processes raw/original input data.\n",
        "\n",
        "augmented_data_model: Processes augmented versions of the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2OmmDFVOgdJ",
        "outputId": "74c56659-a750-4078-b007-c8236d0dacdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-145d36900d23>:4: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  model=MobileNet(weights='imagenet', include_top=False)\n",
            "<ipython-input-12-145d36900d23>:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  augmented_data_model=MobileNet(weights='imagenet', include_top=False)\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.applications import MobileNet\n",
        "\n",
        "model=MobileNet(weights='imagenet', include_top=False)\n",
        "augmented_data_model=MobileNet(weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta4OlNGNPhC0"
      },
      "source": [
        "Global average pooling is applied to extract compact feature vectors from the outputs of both the original data model and the augmented data model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "i-72-d2DOlnE"
      },
      "outputs": [],
      "source": [
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "x=model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "\n",
        "augmented_data_x=augmented_data_model.output\n",
        "augmented_data_x=GlobalAveragePooling2D()(augmented_data_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CfGOJEZPwCH"
      },
      "source": [
        "Creates two separate models for processing original and augmented data, with dense layers added for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CUIXMFtAOrGf"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "\n",
        "x=Dense(50, activation='relu')(x)\n",
        "preds=Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "augmented_data_x=Dense(50, activation='relu')(augmented_data_x)\n",
        "augmented_data_preds=Dense(1, activation='sigmoid')(augmented_data_x)\n",
        "\n",
        "model=Model(inputs=model.input, outputs=preds)\n",
        "augmented_data_model=Model(inputs=augmented_data_model.input, outputs=augmented_data_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z08XsEa0P0Eo"
      },
      "source": [
        "Counts layers that have already been trained and set only new ones for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "w2YklC8iQAS4"
      },
      "outputs": [],
      "source": [
        "not_trainable_layer_count = len(model.layers) -1\n",
        "\n",
        "for layer in model.layers[:not_trainable_layer_count]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[not_trainable_layer_count:]:\n",
        "    layer.trainable=True\n",
        "\n",
        "for layer in augmented_data_model.layers[:not_trainable_layer_count]:\n",
        "    layer.trainable=False\n",
        "for layer in augmented_data_model.layers[not_trainable_layer_count:]:\n",
        "    layer.trainable=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cNRRM_vQOCH"
      },
      "source": [
        "The dataset directory, target image size, and batch size are defined for preparing and processing image data in TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sIsc5hewQb5p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "base_dir = \"/content/maltese-or-poodle/classes2\"\n",
        "image_size = (224, 224)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnPnTDBSQZkA"
      },
      "source": [
        "The code loads and splits image data from base_dir into training (80%) and validation (20%) datasets, resizing images and batching them. It also retrieves and prints the class names for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBl1d0o2TnWl",
        "outputId": "4585b074-076d-4419-ce54-fdbda3734d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 387 files belonging to 2 classes.\n",
            "Using 310 files for training.\n",
            "Found 387 files belonging to 2 classes.\n",
            "Using 77 files for validation.\n",
            "Classes: ['pug', 'whippet']\n"
          ]
        }
      ],
      "source": [
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    base_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    base_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = train_dataset.class_names\n",
        "print(\"Classes:\", class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5WU1fSJQpJk"
      },
      "source": [
        "Sets up a pipeline for augmenting and normalizing images in the training dataset and normalizing the test dataset. This improves generalization during training and ensures consistent input scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QVaC122tT80P"
      },
      "outputs": [],
      "source": [
        "from keras.layers import RandomFlip, RandomRotation, RandomZoom, Rescaling\n",
        "from keras.models import Sequential\n",
        "\n",
        "data_augmentation = Sequential([\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    RandomRotation(0.2),\n",
        "    RandomZoom(0.2),\n",
        "])\n",
        "\n",
        "normalization_layer = Rescaling(1./255)\n",
        "\n",
        "augmented_train_dataset = train_dataset.map(lambda x, y: (data_augmentation(normalization_layer(x)), y))\n",
        "augmented_test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGz8UPQhQ2dB"
      },
      "source": [
        " Optimizes data pipelines by enabling prefetching, allowing data loading and preprocessing to run concurrently with model training or evaluation, improving computational efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wp2x7YT1UBuc"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "augmented_train_dataset = augmented_train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "augmented_test_dataset = augmented_test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5KrCXXcQ_OD"
      },
      "source": [
        " Bompiles both the original and augmented data models with the Adam optimizer, binary cross-entropy loss, and accuracy as the evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DDhHjRaaUG0L"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "augmented_data_model.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSKyb7MQRC19"
      },
      "source": [
        "Sets epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PraQ5uh6DShm"
      },
      "outputs": [],
      "source": [
        "epochs=70"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiR0oeTcRL5N"
      },
      "source": [
        " Trains the models using the training dataset for a specified number of epochs and evaluates it using the validation dataset after each epoch to monitor its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLx36wz4UR0C",
        "outputId": "61742266-5954-479c-94fd-25a2736a995b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4993 - loss: 0.9345 - val_accuracy: 0.4935 - val_loss: 0.9940\n",
            "Epoch 2/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.4665 - loss: 0.9710 - val_accuracy: 0.4935 - val_loss: 0.9839\n",
            "Epoch 3/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.4761 - loss: 0.9613 - val_accuracy: 0.4935 - val_loss: 0.9740\n",
            "Epoch 4/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4740 - loss: 0.9599 - val_accuracy: 0.4935 - val_loss: 0.9645\n",
            "Epoch 5/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4557 - loss: 0.9624 - val_accuracy: 0.4935 - val_loss: 0.9554\n",
            "Epoch 6/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4864 - loss: 0.9229 - val_accuracy: 0.4935 - val_loss: 0.9464\n",
            "Epoch 7/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.4763 - loss: 0.9065 - val_accuracy: 0.4935 - val_loss: 0.9374\n",
            "Epoch 8/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4784 - loss: 0.8940 - val_accuracy: 0.4935 - val_loss: 0.9288\n",
            "Epoch 9/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4554 - loss: 0.9271 - val_accuracy: 0.4935 - val_loss: 0.9203\n",
            "Epoch 10/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.4883 - loss: 0.9013 - val_accuracy: 0.4935 - val_loss: 0.9122\n",
            "Epoch 11/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.5088 - loss: 0.8822 - val_accuracy: 0.4935 - val_loss: 0.9043\n",
            "Epoch 12/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.4999 - loss: 0.8620 - val_accuracy: 0.4935 - val_loss: 0.8964\n",
            "Epoch 13/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.4755 - loss: 0.8882 - val_accuracy: 0.4935 - val_loss: 0.8888\n",
            "Epoch 14/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4947 - loss: 0.8466 - val_accuracy: 0.4935 - val_loss: 0.8816\n",
            "Epoch 15/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5251 - loss: 0.8106 - val_accuracy: 0.4935 - val_loss: 0.8747\n",
            "Epoch 16/70\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5091 - loss: 0.8104"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBM7oxnpOldb"
      },
      "outputs": [],
      "source": [
        "augmented_data_history = augmented_data_model.fit(\n",
        "    augmented_train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=augmented_test_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osJeeCZIRYM2"
      },
      "source": [
        "Loads test images, preprocesses them, and makes predictions using both the original and augmented data models. It then prints out the predicted class (\"poodle\" or \"maltese\") for each test image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2CmhDkxSNmi"
      },
      "outputs": [],
      "source": [
        "model.save(f'{class_names[0]}-or-{class_names[1]}-mobilenet.h5')\n",
        "from google.colab import files\n",
        "files.download(f'{class_names[0]}-or-{class_names[1]}-mobilenet.h5')\n",
        "\n",
        "augmented_data_model.save(f'augmented-data-{class_names[0]}-or-{class_names[1]}-mobilenet.h5')\n",
        "from google.colab import files\n",
        "files.download(f'augmented-data-{class_names[0]}-or-{class_names[1]}-mobilenet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfboJcavUzO-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "test_paths = os.listdir(\"/content/maltese-or-poodle/test\")\n",
        "for path in test_paths:\n",
        "  test_image = image.load_img(f'/content/maltese-or-poodle/test/{path}', target_size = (224, 224))\n",
        "\n",
        "  test_image = image.img_to_array(test_image)\n",
        "  test_image = np.expand_dims(test_image, axis = 0)\n",
        "  test_image = test_image/255\n",
        "\n",
        "  result = model.predict(test_image)\n",
        "  augmented_data_result = augmented_data_model.predict(test_image)\n",
        "\n",
        "  if result[0][0] < 0.5:\n",
        "      prediction = class_names[0]\n",
        "  else:\n",
        "      prediction = class_names[1]\n",
        "\n",
        "  if augmented_data_result[0][0] < 0.5:\n",
        "      augmentedData_prediction = class_names[0]\n",
        "  else:\n",
        "      augmentedData_prediction = class_names[0]\n",
        "\n",
        "  print(f'Prediction: {path} is {prediction}')\n",
        "  print(f'Augmented data prediction: {path} is {augmentedData_prediction}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zfyjo_URweC"
      },
      "source": [
        "Generates a line graph comparing the training and validation accuracy of two models (one trained with original data and the other with augmented data) across multiple epochs, helping to visualize the performance differences between them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xLzd3MdnRc9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "val_loss = history.history['val_loss']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "augmented_data_val_loss = augmented_data_history.history['val_loss']\n",
        "augmented_data_val_accuracy = augmented_data_history.history['val_accuracy']\n",
        "\n",
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(val_loss)\n",
        "ax.plot(augmented_data_val_loss)\n",
        "ax.set_title(\"Validation Loss\")\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(val_accuracy)\n",
        "ax2.plot(augmented_data_val_accuracy)\n",
        "ax2.set_title(\"Validation Accuracy\")\n",
        "ax2.set_xlabel(\"Epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# plt.plot(epochs, val_loss, 'b.', label='Validation Loss')\n",
        "# pl't.plot(epochs, augmented_data_val_loss, 'r.', label='Augmented Data Validation Loss')\n",
        "\n",
        "# plt.plot(epochs, val_accuracy, 'b-', label='Validation Accuracy')\n",
        "# plt.plot(epochs, augmented_data_val_accuracy, 'r-', label='Augmented Data Validation Accuracy')\n",
        "\n",
        "# plt.title('Model Accuracy Comparison')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfWfADzbmw-W"
      },
      "outputs": [],
      "source": [
        "plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9n08MQKsTxr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "val_loss = history.history['val_loss']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "augmented_data_val_loss = augmented_data_history.history['val_loss']\n",
        "augmented_data_val_accuracy = augmented_data_history.history['val_accuracy']\n",
        "\n",
        "epochs = np.array(range(1, len(accuracy) + 1))  # Convert to NumPy array for mathematical operations\n",
        "\n",
        "# Logarithmic regression for Training Accuracy\n",
        "log_fit_acc = np.polyfit(np.log(epochs), accuracy, 1)  # Fit a log-linear model\n",
        "log_fit_aug_acc = np.polyfit(np.log(epochs), augmented_data_accuracy, 1)\n",
        "\n",
        "# Logarithmic regression for Validation Accuracy\n",
        "log_fit_val_acc = np.polyfit(np.log(epochs), val_accuracy, 1)\n",
        "log_fit_aug_val_acc = np.polyfit(np.log(epochs), augmented_data_val_accuracy, 1)\n",
        "\n",
        "# Generate fitted values\n",
        "log_line_acc = log_fit_acc[0] * np.log(epochs) + log_fit_acc[1]\n",
        "log_line_aug_acc = log_fit_aug_acc[0] * np.log(epochs) + log_fit_aug_acc[1]\n",
        "\n",
        "log_line_val_acc = log_fit_val_acc[0] * np.log(epochs) + log_fit_val_acc[1]\n",
        "log_line_aug_val_acc = log_fit_aug_val_acc[0] * np.log(epochs) + log_fit_aug_val_acc[1]\n",
        "\n",
        "# Plot regression lines\n",
        "plt.plot(epochs, log_line_acc, 'b:', label='Log Fit: Training Accuracy')\n",
        "plt.plot(epochs, log_line_aug_acc, 'r:', label='Log Fit: Augmented Training Accuracy')\n",
        "plt.plot(epochs, log_line_val_acc, 'b-.', label='Log Fit: Validation Accuracy')\n",
        "plt.plot(epochs, log_line_aug_val_acc, 'r-.', label='Log Fit: Augmented Validation Accuracy')\n",
        "\n",
        "# Plot details\n",
        "plt.title('Model Accuracy with Logarithmic Regression')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOy/h2jTkaeDyqJiLsyAkXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}